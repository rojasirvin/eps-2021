<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Regresión y efectos causales</title>
    <meta charset="utf-8" />
    <meta name="author" content="Irvin Rojas" />
    <script src="libs/header-attrs-2.9/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs/cide.css" type="text/css" />
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap-grid.min.css" type="text/css" />
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" type="text/css" />
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: title-slide



.title[
# Clase 3. Regresión y efectos causales
]
.subtitle[
## Evaluación de Programas Sociales
]
.author[
### Irvin Rojas &lt;br&gt; [rojasirvin.com](https://www.rojasirvin.com/) &lt;br&gt; [&lt;i class="fab fa-github"&gt;&lt;/i&gt;](https://github.com/rojasirvin) [&lt;i class="fab fa-twitter"&gt;&lt;/i&gt;](https://twitter.com/RojasIrvin) [&lt;i class="ai ai-google-scholar"&gt;&lt;/i&gt;](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&amp;hl=en)
]

.affiliation[
### Centro de Investigación y Docencia Económicas &lt;br&gt; División de Economía
]

---
# Agenda

1. Motivar el uso de regresión para el análisis de efectos de tratamiento

1. Recordatorio de las propiedades de la función de regresión

1. Estudiaremos el supuesto de independencia condicional

1. Veremos un ejemplo de experimento aleatorio para relacionarlo con lo que ya sabemos y para identificar elementos que iremos descubriendo con el tiempo



---

class: inverse, middle, center

# Motivación con efectos constantes


---

# Regresión para la idenfiticación de efectos causales

- Con fines de simplificación, asumamos un efecto de tratamiento constante: `\(y_{1i}-y_{0i}=\rho\)`

- Consideremos el valor observado para un individuo 
`$$y_i=y_{0i}+(y_{1i}-y_{0i})D_i$$`

- Sumemos y restemos `\(E(y_{0i})\)`:

$$
`\begin{aligned}
y_i&amp;=E(y_{0i})+(y_{1i}-y_{0i})D_i+y_{0i}-E(y_{0i}) \\
&amp;=\underbrace{\alpha}_{E(y_{0i})}+\underbrace{\rho}_{(y_{1i}-y_{0i})} D_i + \underbrace{\nu_i}_{y_{0i}-E(y_{0i})}
\end{aligned}`
$$

- Ahora evaluemos:

$$
`\begin{aligned}
&amp;E(y|D_i=1)=\alpha+\rho+E(\nu_i|D_i=1) \\
&amp;E(y|D_i=0)=\alpha+E(\nu_i|D_i=0)
\end{aligned}`
$$

---

# Regresión para la idenfiticación de efectos causales

- Restando

$$
`\begin{aligned}
E(y|D_i=1)-E(y|D_i=0)&amp;=\rho+\overbrace{E(\nu_i|D_i=1)-E(\nu_i|D_i=0)}^{\text{Sesgo de selección}} \\
&amp;=\rho+E(y_{1i}|D_i=1)-E(y_{0i}|D_i=0)
\end{aligned}`
$$
- Es decir, el sesgo de selección es igual a la correlación entre el término de error y `\(D_i\)`

- Y, de acuerdo a la segunda línea, también es igual a la diferencia en el resultado potencial (de no tratamiento), entre aquellos que son tratados y los que no son tratados

- En nuestro ejemplo del hospital, es muy probable que el sesgo de selección sea negativo porque los tratados son quienes tienen peor salud (en el estado no tratado)

- Como vimos antes, con asignación aleatoria, el sesgo de selección desaparece, por lo que una regresión de `\(y_i\)` en `\(D_i\)` estima el efecto causal `\(\rho\)`

---

# El impacto de STAR con regresión

La Tabla 2.2.2 en MHE muestra los efectos de tratamiento estimados con regresión: 


|Variable explicativa | (1) | (2) | (3) | (4) |
|--|:-:|:-:|:-:|:-: |
| `\(T_1\)` | 4.82 | 5.37 | 5.36 | 5.37 |
| | (2.19)| (1.26) | (1.21) | (1.19)
| `\(T_2\)` | 0.12 | 0.29 | 0.53 | 0.31 |
| | (2.23) | (1.13) | (1.09) | (1.07) |
| Efectos fijos de escuela | No | Sí  | Sí | Sí |
|Controles| No | No | `\(X_1\)` | `\(X_1+X_2\)` |

- ¿Cómo se obtienen los resultados de esta tabla?

- ¿Qué se deduce sobre los distintos tratamientos?

---

# Regresión corta y larga

- Con un tratamiento binario y asignado aleatoriamente, podemos estimar el efecto usando una regresión:

`$$y_i=\alpha+\beta T_i + u_i$$`

- Es muy común, sin embargo, usar **controles**

- Si una serie de características `\(X\)` no está correlacionada con `\(T_i\)`, se puede incluir en una versión larga de la regresión antes descrita:

`$$y_i=\alpha+\beta T_i + X_i'\gamma + u_i$$`
- El valor numérico de `\(\hat{\beta}\)` en la regresión larga será muy cercano al obtenido con la regresión corta, pero se incrementa la precisión de los parámetros estimados

- Dado que emplearemos regresión ampliamente en este curso, es necesario fijar algunas ideas sobre cómo entendemos y cómo usamos la regresión en la práctica


---

class: inverse, middle, center

# Conceptos básicos de regresión

---

# Regresión como función de esperanza condicional

- Olvidemos por ahora la causalidad y centremonos en la conexión entre dos variables, `\(y\)` y `\(s\)` (ingreso y educación)

- La **función de esperanza condicional** es una forma de describir la relación entre estas dos variables

- **Función de esperanza condicional**: la FEC de `\(y_i\)` dado un vector de regresores `\(X_i\)` es la esperanza o promedio poblacional de `\(y_i\)` cuando mantenemos fijo `\(X_i\)` y se denota `\(E(y_i|X_i)\)`

- Para representar una realización particular de `\(X_i\)` escribimos `\(X_i=x_i\)`, por lo que la FEC es `\(E(y_i|X_i=x_i)\)`

- Con `\(y_i\)` discreta, la FEC se expresa como

`$$E(y_i|X_i=x_i)=\sum_t t P(y_i=t|X_i=x_i)$$`
---

# Ejemplo de FEC: salarios y educación en Estados Unidos

.pull-left[
- La figura 3.3.1 en MHE muestra la FEC de salarios en Estados Unidos

- Para cada año de educación, vemos cuál es el (log) del ingreso semanal

- La figura muestra dos cosas principales:

  - La clara relación positiva entre salarios y educación
  
  - La gran variabilidad en salarios para un nivel de educación dado

]


.pull-right[
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/fec_mhe.png" alt="Fuente: Angrist &amp;amp; Pischke (2009)" width="100%" /&gt;
&lt;p class="caption"&gt;Fuente: Angrist &amp; Pischke (2009)&lt;/p&gt;
&lt;/div&gt;
]

---

# Algunas propiedades de la FEC

- Las siguientes dos propiedades nos serán útiles para motivar el uso de regresión:

- **Propiedad de descomposición**: cualquier variable aleatoria `\(y_i\)` puede ser descompuesta en una parte explicada por `\(X_i\)` (la FEC) y una parte ortogonal con cualquier función de `\(X_i\)`:

`$$y_i=E(y_i|X_i)+\varepsilon_i$$`
--

- **Propiedad predictiva**: la FEC es el mejor predictor de `\(y_i\)` dado `\(X_i\)` en el sentido de minimizar los errores cuadrados promedio de un problema de predicción:

`$$E(y_i|X_i)=\arg\min_{m(X_i)} E((y_i-m(X_i)^2)$$`
- Pueden ver una prueba muy sencilla en MHE de la propiedad predictiva


---

# Tres razones por las cuales usar regresión

1. **Teorema de la FEC lineal**: si la FEC es lineal, entonces la función de regresión poblacional también lo es. Pueden ver una prueba muy sencilla en MHE

--

1. **Teorema del mejor predictor lineal**: la función `\(X_i'\beta\)` es el mejor predictor lineal de `\(y_i\)` dado `\(X_i\)` en el sentido de mínimos cuadrados. Es decir `$$\beta=\arg\min_b E((y_i-X_i'b) ^2)$$`

--

1. **Teorema de la regresión de la FEC**: la función `\(X_i'\beta\)` es la aproximación lineal de mínimos errores cuadrados promedio de `\(E(y_i|X_i)\)`: `$$\beta=\arg\min_b E((E(y_i|X_i)-X_i'b) ^2)$$`


---

# Interpretación de estos teoremas

- El teorema 1 es muy restrictivo, solo aplica cuando la FEC es en sí misma lineal

--

- Los teoremas 2 y 3 son mucho menos restrictivos

- El teorema 2 nos dice que, así como la FEC es el mejor predictor no restringido (de entre las funciones `\(m\)` en la propiedad predictiva de la FEC), la regresión es el **mejor predictor lineal**

- El teorema 3 nos dice que si pensamos en cambio en aproximar `\(E(y_i|X_i)\)`, incluso aunque la FEC no sea lineal, la regresión nos da la mejor aproximación lineal

--

- El teorema 3 es lo más cercano a como interpretamos la regresión en evaluación pues más que querer predicciones de `\(y\)` para un individuo `\(i\)`, nos interesa la relación promedio entre las variables

- El teorema 2 nos hace pensar menos en la relación económica entre variables y más en una relación mecánica

---

# Propiedades del estimador de MCO

- En la práctica, no conocemos la FEC

- Los teoremas antes vistos nos dicen que una forma de aproximarla es usando regresión, es decir, quisiéramos conocer `\(\beta=E(X_iX_i')^{-1}E(X_iy_i)\)`, un objeto poblacional

- En la práctica aproximamos `\(\beta\)` con su análogo muestral: `\(\hat{\beta}_{MCO}=(X'X)^{-1}(X'Y)\)`

--

- Con algo de álbebra, escribimos el estimador de MCO como `$$\hat{\beta}_{MCO}=\beta +\left(\sum x_ix_i'\right)^{-1}\left(\sum x_i u_i\right)$$`

- Multiplicando por 1 el segundo término:
`$$\hat{\beta}_{MCO}=\beta +\left(\frac{1}{N}\sum x_ix_i'\right)^{-1}\left(\frac{1}{N}\sum x_i u_i\right)$$`
- Esta representación con **promedios** es útil para usar leyes de grandes números (LGN) y teoremas de límite central (TLC)

---

# Consitencia

- Queremos conocer la probabilidad límite del estimador de MCO:

`$$p\lim\hat{\beta}_{MCO}=\beta +\left(p\lim\left(\frac{1}{N}\sum x_ix_i'\right)^{-1}\right)\left(p\lim\left(\frac{1}{N}\sum x_i u_i\right)\right)$$`
- Si se puede aplica una LGN a `\(x_ix_i'\)`, entonces sabemos que el promedio `\(\frac{1}{N}\sum x_ix_i'\)` converge a una matriz finita no nula

- Entonces, el estimador de MCO es consistente si `\(p\lim(\frac{1}{N}\sum x_i u_i)=0\)`

- Escribimos `\(\hat{\beta}_{MCO}\xrightarrow{p}\beta\)`

---

# Disitribución límite

- Reescribimos el estimador de MCO como:
`$$\sqrt{N}(\hat{\beta}-\beta)=(N^-{1}X'X)^{-1}N^{-1/2}X'u$$`
- Para mostrar consistencia ya dijimos que `\(N^{-1}X'X\)` converge a una matriz finita y no nula

- Si podemos aplicar un TLC a `\(X'u\)`, el segundo término tiene una distribución asintótica normal con media cero y varianza `\(p\lim\frac{1}{N}X'uu'X\)`

--

- Por lo tanto, la distribución asintótica del estimador de MCO es

`$$\hat{\beta}_{MCO}\stackrel{a}{\sim}\mathcal{N}\left(\beta,(X'X)^{-1}X'uu'X(X'X)^{-1}\right)$$`
---

# Breve recordatorio de inferencia

- Tenemos que estimar también la varianza del estimador de MCO

- En un famoso artículo, White (1980) muestra que podemos estimar consistentemente `\(\hat{V}(\hat{\beta})\)` usando:

 `$$\hat{V}(\hat{\beta})=(X'X)^{-1}\left(\sum_i \hat{u}_i^2x_ix_i'\right)(X'X)^{-1}$$`
- Esto es a lo que conocemos como la matriz de varianzas robusta a heterocedasticidad

- Son robutos porque no hacemos supuestos sobre la distribución de los errores

- En muy raras ocasiones, si asumimos errores independientes e identicamente distribuidos:

 `$$\hat{V}^H(\hat{\beta})=\hat{s}^2(X'X)^{-1}$$`
donde `\(\hat{s}\)` es la varianza muestral


---

class: inverse, middle, center

# Regresión y causalidad


---

# Regresión y causalidad

- Lo que hemos visto hasta ahora nos dice que la regresión es nuestro mejor aproximación lineal a la FEC

- Pero la regresión será causal solo si la FEC es causal

- Con lo que hemos visto del modelo de resultados potenciales, podemos tener una interpretación causal de la FEC

--

- La **FEC es causal** cuando describe las diferencias en resultados potenciales promedio para una población de referencia fija (Angrist and Pischke, 2009)

- En la relación entre educación y salarios, una FEC causal describiría lo que un individuo ganaría con distintos niveles de educación


---

# Supuesto de independencia condicional

- El **supuesto de independencia condicional** significa que, condicional en una serie de características `\(X_i\)`, el sesgo de selección desaparece:

`$$\{y_{0i},y_{1i}\}\perp D_i | X_i$$`

--

- Supongamos que `\(T_i\)` es ir a la universidad y la variable de interés es el ingreso

- Sabemos que la comparación observacional nos da:

$$
`\begin{aligned}
E(y_i|D_i=1)-E(y_i|D_i=0)=&amp;\overbrace{ E(y_{1i}-y_{0i}|D_i=1)}^{\text{Efecto promedio en los tratados}}+\\&amp; \underbrace{E(y_{0i}|D_i=1)-E(y_{oi}|D_i=0)}_{\text{Sesgo de selección}}
\end{aligned}`
$$
- Es posible que aquellos que no fueron a la universidad de todos modos hubieran tenido un mayor salario, por lo que el sesgo de selección es positivo


---

# Supuesto de independencia condicional
- El SIC implica que si hacemos la comparación condicional en `\(X_i\)`, el sesgo desaparece


$$
`\begin{aligned}
E(y_i|X_i,D_i=1)-E(y_i|X_i,D_i=0)=E(y_{1i}-y_{0i}|X_i)
\end{aligned}`
$$

- Para generalizar el concepto cuando la variable tiene más de dos valores (como con la educación `\(s_i\)`), escribamos `\(Y_{si}\equiv f_i(s)\)`

- Esta función nos dice cuál sería el ingreso de `\(i\)` bajo todos los posibles niveles de `\(s\)`

- En este caso, el SIC se convierte en:


`$$Y_{si}\perp s_i | X_i$$`
- En diseños experimentales, el SIC surge porque el tratamiento se asigna de forma aleatoria

- Pero con datos *observacionales*, el SIC significa que `\(s_i\)` es *casi como si fuera asignado de manera aleatoria* cuando condicionamos en `\(X_i\)`

---

# Supuesto de independencia condicional

- En los datos solo observamos `\(Y_i=f_i(s_i)\)`


- Dado el SIC, podemos hacer comparaciones de ingreso promedio para distintos niveles de educación:
`$$E(Y_i|X_i,s_i=s)-E(Y_i|X_i,s_i=s-1)=E(f_i(s)-f_i(s-1)|X_i)$$`
---

# Regresión para hacer las comparasiones

- Notemos que lo impráctico de esto es que tendríamos que hacer comparaciones en pares y luego tratar de hacer un promedio ponderado por el número de individuos en cada nivel de educación

--

- Supongamos una función causal para el ingreso, `\(f_i(s)=\alpha+\rho s+\nu_i\)`, que indica lo que un individuo ganaría para todo valor de `\(s\)` (y no solo el valor realizado `\(s_i\)`)

- La única parte aleatoria es el error con media cero `\(\nu_i\)`, que captura los factores no observados que afentan los ingresos

- Sustituyendo el valor observado:
`$$Y_i=\alpha+\rho s_i+\nu_i$$`
- `\(s_i\)` puede estar correlacionado con los resultados potenciales `\(f_i(s)\)`, es decir, correlaciondo con el error `\(\nu_i\)`


---

# Regresión para hacer las comparasiones

- Supongamos que el SIC se cumple dado un vector `\(X_i\)`

- Descompongamos el error en una función lineal de las características `\(X_i\)` y un error `\(u_i\)`:
`$$\nu_i=X_i'\gamma+u_i$$`

donde se asume que `\(E(\nu_i|X_i)=X_i'\gamma\)` y donde `\(u_i\)` y `\(X_i\)` no están correlacionados

- Si se cumple el SIC, entonces:

$$
`\begin{aligned}
E(f_i(s)|X_i,s_i)=E(f_i(s)|X_i)&amp;=\alpha+\rho s+E(\nu_i|X_i) \\
&amp;=\alpha+\rho s + X_i'\gamma
\end{aligned}`
$$
- Es decir, en el modelo de regresión causal
`\(Y_i=\alpha+\rho s_i+ X_i'\gamma+u_i\)`, `\(u_i\)` no está correlacionado con los regresores `\(X_i\)` y `\(s_i\)`

- `\(\rho\)` es el efecto causal de interés

- El supuesto clave es que la única razón por la cual `\(\nu_i\)` y `\(s_i\)` están correlacionados es `\(X_i\)`


---

class: inverse, middle, center

# Efectivo o condicionales


---

# Efectivo o condicionales (Baird, McIntosh &amp; Özler, 2011)



- ¿Cuál es la diferencia entre un CCT y un UCT?

- ¿Cuál es la racionalidad económica de los CCT?

  - Fallas de mercado
  
  - Información asimétrica o incompleta
  
  - Factibilidad política
  
- Críticas a los CCT



---

# El experimento ideal

- Si queremos saber qué funciona mejor, ¿cuál es el experimento ideal?

--

- Ya hemos visto varios elementos para interpretar los resultados del trabajo

  - Integridad del diseño
  
  - Efectos de tratamiento usando regresiones

--

- Este artículo contiene muchos elementos que no hemos visto, pero veremos cómo a lo largo del curso nos haremos de herramientas para entender la literatura

  - `\(z\)`-scores
  
  - Interpretación de *complidores* y *no cumplidores*
  
  - Errores agrupados

---

# El programa

- ¿En qué consiste?

--
  - Condicionales en el brazo CCT
  
  - Sin requerimientos de asistencia escolar en el brazo UCT
--

- Lugar de implementación: Malawi, distrito de Zomba

- 550 áreas de enumeración (EA) con aproximadamente 250 hogares cada una

--

- ¿A qué nivel se asginó el tratamiento?

--

- Se seleccionaron 176 EA para el estudio: 46 en CCT, 27 en UCT y 88 en C

--

- ¿Quiénes fueron elegibles?
  - Mujeres de 13-22 años
  - Nunca han estado casadas
  - Criterio de escolaridad

---

# Datos

- Encuesta anual para obtener `\(X\)`

- En la R2 encuesta a todas las escuelas

- En la R3 encuesta a una submuestra

- Lista de asistencia

- Prueba de matemáticas e ingles en R3

---

# Atrición

- ¿Qué es atrición?

--

- ¿Qué observamos?

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/cash_condition_table1.png" alt="Fuente: Baird, McIntosh &amp;amp; Özler (2011)" width="70%" /&gt;
&lt;p class="caption"&gt;Fuente: Baird, McIntosh &amp; Özler (2011)&lt;/p&gt;
&lt;/div&gt;


---

# Atrición

- ¿Cómo se obtienen los resultados de la Tabla 1

`$$y_i=\alpha+\beta_C C_i+\beta_U U_i + e_i$$`

donde `\(y_i\)` toma el valor de 1 si la observación estaba en la línea base y también en la R3, por ejemplo

--

- ¿Cómo determinamos que hay diferencias significativas?

- Por ejemplo, ¿qué significa el 0.29* (error estándar de 0.016) en la primera fila de la columna (3)?



---

# Pruebas de balance

- Un aspecto que siempre revisamos cuando leemos resultados experimentales


- ¿Qué observamos?

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/cash_condition_table2b.png" alt="Fuente: Baird, McIntosh &amp;amp; Özler (2011)" width="70%" /&gt;
&lt;p class="caption"&gt;Fuente: Baird, McIntosh &amp; Özler (2011)&lt;/p&gt;
&lt;/div&gt;

---

# Pruebas de balance

- ¿Cómo obtenemos estos resultados en la práctica?

--

`$$x_i=\alpha+\beta_C C_i+\beta_U U_i+u_i$$`
--

- Otros aspectos técnicos:

  - Errores estándar agrupados a nivel EA
  
  - Indicadores de estrato de aleatorización (ciudad, semiurbano, rural)
  
  
---

# Efectos de tratamiento

- Veamos los efectos en la asistencia usando las listas

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/cash_condition_table5.png" alt="Fuente: Baird, McIntosh &amp;amp; Özler (2011)" width="58%" /&gt;
&lt;p class="caption"&gt;Fuente: Baird, McIntosh &amp; Özler (2011)&lt;/p&gt;
&lt;/div&gt;

---

# Efectos de tratamiento

- ¿Cómo obtenemos los efectos de tratamiento?

`$$y_i=\alpha+\beta_C C_i+\beta_U U_i +X_i'\gamma+u_i$$`
- `\(X_i\)` son las características en la línea base

- Como el tratamiento se asignó de manera aleatoria, esperamos que `\(X_i\)` no esté correlacionado con el error, pero que sí mejore la precisión de los estimadores

---

# Efectos en pruebas académicas

- Muchas veces se emplean *z-scores*

- Supongamos que en un test los alumnos tienen una calificación `\(y_i\)`

- Definimos `\(z_i=\frac{y_i-\bar{y}}{de(y)}\)`

- Tiene la ventaja de interpretación: `\(\beta\)` es el cambio en desviaciones estándar


---

# Efectos en matrimonios y embarazos

- Efectos grandes en UCT, pero no hay efectos de CCT

- Parece en contra de lo que hubiéramos esperado

- Interpretación basada en *cumplidores* y *no cumplidores*, lo cual veremos más adelante en el curso




---
# Próxima sesión

- Hablaré sobre las medidas de variabilidad para realizar inferencia

  - MM, Capítulo 1, Apéndice
  
- Haré algunas definiciones de la literatura de efectos de tratamiento

  - CT, Capítulo 25, Secciones 1 y 2
  
- Veremos un ejemplo un tanto distinto: un proyecto a escala masiva

  - Banerjee, A., Duflo, E., Goldberg, N., Karlan, D., Osei, R., Parienté, W., Shapiro, J., Thuysbaert, B. &amp; Udry, C. (2015). A multifaceted program causes lasting progress for the very poor: Evidence from six countries. *Science*, 348(6236), 1260799.
  

---

class: center, middle

Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script src="libs/cols_macro.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
